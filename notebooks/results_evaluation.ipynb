{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importResults(results):\n",
    "    memory = []\n",
    "    memory.append(results[1])\n",
    "    memory.append(results[2])\n",
    "    memory.append(results[3])\n",
    "    return memory\n",
    "\n",
    "def getSensSpec(conf_matrix):\n",
    "    sensitivity = conf_matrix[1,1]/(conf_matrix[1,1]+conf_matrix[1,0])\n",
    "    specificity = conf_matrix[0,0]/(conf_matrix[0,0]+conf_matrix[0,1])\n",
    "    return sensitivity, specificity\n",
    "\n",
    "def getMetrics(results_list):\n",
    "    from sklearn.metrics import confusion_matrix \n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from statistics import mean\n",
    "    conf_matrix = confusion_matrix(results_list[1],results_list[2])\n",
    "    sens, spec = getSensSpec(conf_matrix)\n",
    "    #print(\"Confusion matrix is\\n\", conf_matrix)\n",
    "    #print(\"Calculated precision is \",precision_score(results_list[1],results_list[2],average = \"macro\"),\"\\n\")\n",
    "    #print(\"Accuracy is \",pd.DataFrame(results_list[0]).mean(),\"\\n\")\n",
    "    #print(\"F1 score is \",f1_score(results_list[1],results_list[2]),\"\\n\")\n",
    "    #print(\"Sensitivity is \",sens,\"\\n\")\n",
    "    #print(\"Specificity is \",spec,\"\\n\")\n",
    "    print(classification_report(results_list[1],results_list[2],digits = 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jkondek/thesis/notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bech_res_NB300_upsample.pkl', 'bech_res_NB300_lemma_upsample.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file = os.listdir(\"../results\")\n",
    "results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.read_pickle(\"../results/\" + results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n",
      "CNN.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.154     0.048     0.074       124\n",
      "           1      0.826     0.945     0.882       595\n",
      "\n",
      "    accuracy                          0.790       719\n",
      "   macro avg      0.490     0.496     0.478       719\n",
      "weighted avg      0.710     0.790     0.742       719\n",
      "\n",
      "test\n",
      "*************\n",
      "CNN_lemma.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.162     0.048     0.075       124\n",
      "           1      0.827     0.948     0.883       595\n",
      "\n",
      "    accuracy                          0.793       719\n",
      "   macro avg      0.495     0.498     0.479       719\n",
      "weighted avg      0.712     0.793     0.744       719\n",
      "\n",
      "test\n",
      "*************\n",
      "CNN_lemma_sent.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "CNN_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.167     0.169     0.168       124\n",
      "           1      0.826     0.824     0.825       595\n",
      "\n",
      "    accuracy                          0.711       719\n",
      "   macro avg      0.496     0.496     0.496       719\n",
      "weighted avg      0.713     0.711     0.712       719\n",
      "\n",
      "test\n",
      "*************\n",
      "CNN_sent.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "CNN_sent_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.300     0.024     0.045       124\n",
      "           1      0.829     0.988     0.902       595\n",
      "\n",
      "    accuracy                          0.822       719\n",
      "   macro avg      0.565     0.506     0.473       719\n",
      "weighted avg      0.738     0.822     0.754       719\n",
      "\n",
      "test\n",
      "*************\n",
      "CNN_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.136     0.137     0.137       124\n",
      "           1      0.820     0.818     0.819       595\n",
      "\n",
      "    accuracy                          0.701       719\n",
      "   macro avg      0.478     0.478     0.478       719\n",
      "weighted avg      0.702     0.701     0.701       719\n",
      "\n",
      "test\n",
      "*************\n",
      "KNN_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.143     0.040     0.063       124\n",
      "           1      0.826     0.950     0.884       595\n",
      "\n",
      "    accuracy                          0.793       719\n",
      "   macro avg      0.484     0.495     0.473       719\n",
      "weighted avg      0.708     0.793     0.742       719\n",
      "\n",
      "test\n",
      "*************\n",
      "NB300.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "NB300_lemma.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "NB300_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.008     0.016       124\n",
      "           1      0.829     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.829       719\n",
      "   macro avg      0.914     0.504     0.461       719\n",
      "weighted avg      0.858     0.829     0.753       719\n",
      "\n",
      "test\n",
      "*************\n",
      "NB300_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.827     0.998     0.905       595\n",
      "\n",
      "    accuracy                          0.826       719\n",
      "   macro avg      0.414     0.499     0.452       719\n",
      "weighted avg      0.685     0.826     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.535     0.185     0.275       124\n",
      "           1      0.851     0.966     0.905       595\n",
      "\n",
      "    accuracy                          0.832       719\n",
      "   macro avg      0.693     0.576     0.590       719\n",
      "weighted avg      0.796     0.832     0.796       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM1000_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.419     0.419     0.419       124\n",
      "           1      0.879     0.879     0.879       595\n",
      "\n",
      "    accuracy                          0.800       719\n",
      "   macro avg      0.649     0.649     0.649       719\n",
      "weighted avg      0.800     0.800     0.800       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM300.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.483     0.226     0.308       124\n",
      "           1      0.855     0.950     0.900       595\n",
      "\n",
      "    accuracy                          0.825       719\n",
      "   macro avg      0.669     0.588     0.604       719\n",
      "weighted avg      0.791     0.825     0.798       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM300_lemma.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.464     0.210     0.289       124\n",
      "           1      0.852     0.950     0.898       595\n",
      "\n",
      "    accuracy                          0.822       719\n",
      "   macro avg      0.658     0.580     0.594       719\n",
      "weighted avg      0.785     0.822     0.793       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM300_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.425     0.524     0.469       124\n",
      "           1      0.896     0.852     0.873       595\n",
      "\n",
      "    accuracy                          0.796       719\n",
      "   macro avg      0.660     0.688     0.671       719\n",
      "weighted avg      0.815     0.796     0.804       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM300_lemma_upsample_2.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.386     0.532     0.447       124\n",
      "           1      0.894     0.824     0.857       595\n",
      "\n",
      "    accuracy                          0.773       719\n",
      "   macro avg      0.640     0.678     0.652       719\n",
      "weighted avg      0.807     0.773     0.787       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM300_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.406     0.524     0.458       124\n",
      "           1      0.894     0.840     0.867       595\n",
      "\n",
      "    accuracy                          0.786       719\n",
      "   macro avg      0.650     0.682     0.662       719\n",
      "weighted avg      0.810     0.786     0.796       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM600_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.433     0.468     0.450       124\n",
      "           1      0.887     0.872     0.880       595\n",
      "\n",
      "    accuracy                          0.803       719\n",
      "   macro avg      0.660     0.670     0.665       719\n",
      "weighted avg      0.809     0.803     0.805       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM_lemma.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.476     0.161     0.241       124\n",
      "           1      0.846     0.963     0.901       595\n",
      "\n",
      "    accuracy                          0.825       719\n",
      "   macro avg      0.661     0.562     0.571       719\n",
      "weighted avg      0.783     0.825     0.787       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.522     0.290     0.373       124\n",
      "           1      0.865     0.945     0.903       595\n",
      "\n",
      "    accuracy                          0.832       719\n",
      "   macro avg      0.693     0.617     0.638       719\n",
      "weighted avg      0.805     0.832     0.811       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVM_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.536     0.298     0.383       124\n",
      "           1      0.866     0.946     0.904       595\n",
      "\n",
      "    accuracy                          0.834       719\n",
      "   macro avg      0.701     0.622     0.644       719\n",
      "weighted avg      0.809     0.834     0.815       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVMem.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVMem_lemma.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVMem_lemma_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.211     0.032     0.056       124\n",
      "           1      0.829     0.975     0.896       595\n",
      "\n",
      "    accuracy                          0.812       719\n",
      "   macro avg      0.520     0.504     0.476       719\n",
      "weighted avg      0.722     0.812     0.751       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVMem_sent.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVMem_sent_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n",
      "*************\n",
      "SVMem_upsample.pkl\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       124\n",
      "           1      0.828     1.000     0.906       595\n",
      "\n",
      "    accuracy                          0.828       719\n",
      "   macro avg      0.414     0.500     0.453       719\n",
      "weighted avg      0.685     0.828     0.749       719\n",
      "\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jkondek/miniconda3/envs/protonets/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "results_file = os.listdir(\"../results\")\n",
    "for path in sorted(results_file):\n",
    "    try:\n",
    "        results = pd.read_pickle(\"../results/\" + path)\n",
    "        print(\"*************\")\n",
    "        print(re.sub(\"bech_res_\",\"\",path))\n",
    "        results_list = importResults(results)\n",
    "        print(\"test\")\n",
    "        getMetrics(results_list)\n",
    "        print(\"test\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = importResults(\"benchmarking_results/test/all_accuracies_test1.pkl\",\n",
    "                             \"benchmarking_results/test/actual_list_test1.pkl\",\n",
    "                             \"benchmarking_results/test/predicted_list_test1.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######proces spajania vysvetleny\n",
    "#prve treba vyriesit, ze results[1] a results[2] su zakodovane ako onehot\n",
    "#to vyriesis s cyklom pouzitim premennej transform\n",
    "#potom spravime novy objekt results vuzitim new results\n",
    "#to iste spravime pre druhu cast vysledkov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def fromOnehot(results_sublist):\n",
    "    import numpy as np\n",
    "    transformed = []\n",
    "    for index in range(0,len(results_sublist)):\n",
    "        transformed.append(np.argmax(results_sublist[index]))\n",
    "    return transformed\n",
    "\n",
    "def getResults(results):\n",
    "    new_results = []\n",
    "    new_results.append(results[0])\n",
    "    for sublist in range(1,3):\n",
    "        new_results.append(fromOnehot(results[sublist]))\n",
    "    return new_results\n",
    "        \n",
    "def join2ResultLists(results1,results2):\n",
    "    transformed1 = getResults(results1)\n",
    "    transformed2 = getResults(results2)\n",
    "    all_accuracies = transformed1[0] + transformed2[0]\n",
    "    actual_list = transformed1[1] + transformed2[1]\n",
    "    predicted_list = transformed1[2] + transformed2[2]\n",
    "    return all_accuracies, actual_list, predicted_list\n",
    "\n",
    "all_accuracies, actual_list, predicted_list = join2ResultLists(results_list,results2)\n",
    "\n",
    "with open('benchmarking_results/all_accuracies_total.pkl', 'wb') as f:\n",
    "            pickle.dump(all_accuracies, f)\n",
    "        \n",
    "with open('benchmarking_results/actual_list_total.pkl', 'wb') as f:\n",
    "            pickle.dump(actual_list, f)\n",
    "\n",
    "with open('benchmarking_results/predicted_list_total.pkl', 'wb') as f:\n",
    "            pickle.dump(predicted_list, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
